{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==2.2.3 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib==3.10.0 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: statsmodels==0.14.4 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from pandas==2.2.3) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from pandas==2.2.3) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from matplotlib==3.10.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from matplotlib==3.10.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from matplotlib==3.10.0) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from matplotlib==3.10.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from matplotlib==3.10.0) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from matplotlib==3.10.0) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from matplotlib==3.10.0) (3.2.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from statsmodels==0.14.4) (1.15.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from statsmodels==0.14.4) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marti\\pycharmprojects\\machinelearning_bootcamp\\.env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy==2.2.3 pandas==2.2.3 matplotlib==3.10.0 statsmodels==0.14.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A time series is a sequence of data points collected over time, typically at regular intervals (E.g. stock prices, weather, or sales figures over a specified period). Time series data is characterized by its chronological order, which allows for the analysis of trends, patterns, and seasonal variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5bPb47x8Jp5"
   },
   "source": [
    "## Dates in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xo4uGRtO734J",
    "outputId": "1064b3f9-7c9d-487a-d290-c340e7e9b948"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2509, 9, 1, 22, 43, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "now = datetime.now()\n",
    "now.day\n",
    "\n",
    "custom_date = datetime(2023, 5, 17, 15, 30, 0)\n",
    "custom_date.strftime('%d-%m-%y')\n",
    "\n",
    "date_str = \"17-05-2023 21:15:13\"\n",
    "datetime.strptime(date_str, '%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "now + timedelta(hours=100)\n",
    "\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "date(2020, 5, 15) + relativedelta(months=5)\n",
    "\n",
    "unix = 17030299383\n",
    "datetime.utcfromtimestamp(unix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INo0zXeveAFQ"
   },
   "source": [
    "## Time Series in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ugjz5XaeCWd",
    "outputId": "c599b00d-9c68-4220-b888-98cf927705f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2024-01-31', '2024-02-29', '2024-03-31', '2024-04-30',\n",
       "               '2024-05-31', '2024-06-30', '2024-07-31', '2024-08-31',\n",
       "               '2024-09-30', '2024-10-31', '2024-11-30', '2024-12-31'],\n",
       "              dtype='datetime64[ns]', freq='ME')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp(\"2024-02-11\")\n",
    "\n",
    "pd.Timestamp.now(tz=\"UTC\")\n",
    "\n",
    "date_range = pd.date_range(start=\"2024-01-01\", periods=12, freq=\"ME\")\n",
    "\n",
    "date_range.to_period('M').to_timestamp('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNE8E1euAjne",
    "outputId": "b1cb1656-5954-44f0-940b-888e13933ac2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1    165\n",
       "2    364\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"date_str\": [\"2023-01-01\", \"2023-06-15\", \"2023-12-31\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['date'] = pd.to_datetime(df[\"date_str\"])\n",
    "\n",
    "df[\"date_utc\"] = df[\"date\"].dt.tz_localize(\"UTC\")  # Set UTC time zone\n",
    "df[\"date_ny\"] = df[\"date_utc\"].dt.tz_convert(\"America/New_York\") \n",
    "df[\"date_ny\"]\n",
    "\n",
    "df[(df[\"date\"] >= \"2023-01-01\") & (df['date'] < \"2023-06-30\")]\n",
    "\n",
    "df[\"year\"] = df['date'].dt.year\n",
    "\n",
    "(df[\"date\"] - df[\"date\"].min()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2YHuNbEBg-p",
    "outputId": "54340138-9478-4929-c3b0-25a3407c13cf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m date_range \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2023-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m, periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m365\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Daily frequency\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m: date_range, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(date_range))}\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "date_range = pd.date_range(start=\"2023-01-01\", periods=365, freq=\"D\")  # Daily frequency\n",
    "data = {\"date\": date_range, \"value\": np.random.randint(10, 100, size=len(date_range))}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.set_index('date')\n",
    "\n",
    "df.asfreq('h')\n",
    "\n",
    "df.resample(rule='YE').sum()\n",
    "\n",
    "df.groupby(pd.Grouper(freq=\"W-MON\")).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=\"2023-01-01\", periods=12, freq=\"ME\")\n",
    "sales = np.random.randint(100, 500, size=len(date_range))\n",
    "\n",
    "df = pd.DataFrame({\"date\": date_range, \"sales\": sales}).set_index(\"date\")\n",
    "\n",
    "print(df[\"sales\"])\n",
    "print(df[\"sales\"].shift(1))\n",
    "print(df[\"sales\"].shift(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYsg7RbS_P6Y"
   },
   "source": [
    "## Time Series Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfgRUVdOGKp7"
   },
   "source": [
    "The **level** is the baseline component that is present in any time series. Plotted without other components, it would be a straight line. \n",
    "\n",
    "A **trend** represents a long-term increase or decrease in the data.\n",
    "\n",
    "A **seasonality** denotes that a time series is affected by one or more seasonal factors of a fixed and known period, such as the time of the year.\n",
    "\n",
    "A **cycle** occurs when there are rises and falls in the data that are not of a fixed frequency and lasts multiple years, usually due to economic conditions.\n",
    "\n",
    "The **error** component is the residual unexplainable component that \"remains\" after accounting for the other components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "NLONf4Zk_Mwc",
    "outputId": "c11296c4-ffb8-461c-91b2-f3008422a4bb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a date range (daily observations over two years)\n",
    "date_range = pd.date_range(start=\"2022-01-01\", periods=730, freq=\"D\")\n",
    "\n",
    "# 1️⃣ Time Series with Seasonality Only (e.g., Monthly Temperature Cycle)\n",
    "seasonality = 100 + 10 * np.sin(2 * np.pi * date_range.dayofyear / 365) + np.random.normal(0, 5, 730)\n",
    "\n",
    "# 2️⃣ Time Series with Trend Only\n",
    "trend = np.linspace(15, 18, 730) + np.random.normal(0, 0.2, 730)\n",
    "\n",
    "# 3️⃣ Time Series with Both Trend & Seasonality (e.g., Sales Data)\n",
    "trend_seasonality = (50 + 0.05 * np.arange(730) +\n",
    "                     20 * np.sin(2 * np.pi * date_range.dayofyear / 365) +  # Stronger seasonality\n",
    "                     np.random.normal(0, 7, 730))\n",
    "\n",
    "# 4️⃣ Time Series with Neither Trend nor Seasonality (Pure White Noise)\n",
    "white_noise = np.random.normal(0, 1, 730)  # Random values with no pattern\n",
    "\n",
    "# Create a DataFrame for easy handling\n",
    "df = pd.DataFrame({\n",
    "    \"Date\": date_range,\n",
    "    \"Seasonality\": seasonality,\n",
    "    \"Trend\": trend,\n",
    "    \"Trend + Seasonality\": trend_seasonality,\n",
    "    \"White Noise\": white_noise\n",
    "})\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Plotting the time series\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(df.index, df[\"Trend\"], label=\"\", color=\"red\")\n",
    "plt.title(\"Time Series with Trend\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(df.index, df[\"Seasonality\"], label=\"\", color=\"blue\")\n",
    "plt.title(\"Time Series with Seasonality\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(df.index, df[\"Trend + Seasonality\"], label=\"\", color=\"green\")\n",
    "plt.title(\"Time Series with Both Trend & Seasonality\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(df.index, df[\"White Noise\"], label=\"\", color=\"purple\")\n",
    "plt.title(\"Time Series with Neither Trend Nor Seasonality\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ciclo (difficile da vedere in un grafico)\n",
    "# Q: una time series può avere più periodi stagionali? Esempio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hS0V-OU4ugia"
   },
   "source": [
    "## Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gL7o-LN1HOBp"
   },
   "source": [
    "Autocorrelation measures the linear relationship between lagged values of a time series.\n",
    "\n",
    "The autocorrelation function (ACF) is used to see how the correlations change depending on the lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "QGGdF0DI0KOO",
    "outputId": "204e23cd-0301-4894-ac3c-930291ac821a"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "plot_acf(df[\"Trend\"], lags=365, alpha=None, zero=False, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"ACF: Trend Only\")\n",
    "\n",
    "plot_acf(df['Seasonality'], lags=365, alpha=None, zero=False, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"ACF: Seasonality Only\")\n",
    "\n",
    "plot_acf(df[\"Trend + Seasonality\"], lags=365, alpha=None, zero=False, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"ACF: Trend + Seasonality\")\n",
    "\n",
    "plot_acf(df[\"White Noise\"], lags=365, alpha=None, zero=False, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"ACF: White Noise (No Trend, No Seasonality)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r9baUjssgqKV"
   },
   "source": [
    "## Time Series Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE83l7P_I4H7"
   },
   "source": [
    "If the data shows variation that increases or decreases with the level of the series, then a transformation can be useful. In general, making the size of the seasonal variation about the same across the whole series makes the forecasting model simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKooy263iSiA"
   },
   "source": [
    "### Logarithmic Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "i_06BEtngvHW",
    "outputId": "28cca938-b24e-4804-8014-1be371db1757"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "date_range = pd.date_range(\"2010-01\", periods=120, freq=\"ME\")\n",
    "\n",
    "trend = np.linspace(10, 1000, 120)\n",
    "\n",
    "seasonality = (0.2 * trend) * np.sin(2 * np.pi * date_range.month / 12)\n",
    "\n",
    "noise = np.random.normal(0, 0.1 * trend, 120)\n",
    "\n",
    "time_series = trend + seasonality + noise\n",
    "\n",
    "log_time_series = np.log(time_series)\n",
    "\n",
    "df = pd.DataFrame({\"Date\": date_range, \"Original\": time_series, \"Log_Transformed\": log_time_series})\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Plot original and log-transformed series\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 6), sharex=True)\n",
    "\n",
    "# Original series\n",
    "axes[0].plot(df.index, df[\"Original\"], label=\"Original Series\", color=\"black\")\n",
    "axes[0].set_title(\"Original Time Series (Increasing Variability)\")\n",
    "axes[0].set_ylabel(\"Value\")\n",
    "\n",
    "# Log-transformed series\n",
    "axes[1].plot(df.index, df[\"Log_Transformed\"], label=\"Log-Transformed Series\", color=\"blue\")\n",
    "axes[1].set_title(\"Log-Transformed Time Series (Stabilized Variance)\")\n",
    "axes[1].set_ylabel(\"Log(Value)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOXTOcFZiWxX"
   },
   "source": [
    "### Moving Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Vfq7oZdKv8d"
   },
   "source": [
    "A moving average of order $m$ is an estimate of the trend-cycle at time $t$, obtained by averaging values of the time series within $k$ periods of $t$, where $k = (m - 1) / 2$. E.g. a 3-MA averages the middle observation, one observation before and one after. Averaging eliminates some of the randomness in the data, leaving a smoother time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "6i9l6v5riQga",
    "outputId": "4fc4b024-bd08-4ba0-c0ee-3db47b04510a"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "date_range = pd.date_range(start=\"2015-01\", periods=60, freq=\"ME\")\n",
    "\n",
    "trend = np.linspace(50, 200, 60)\n",
    "\n",
    "seasonality = 20 * np.sin(2 * np.pi * date_range.month /12)\n",
    "\n",
    "noise = np.random.normal(0, 10, 60)\n",
    "\n",
    "time_series = trend + seasonality + noise\n",
    "\n",
    "df = pd.DataFrame({'Date': date_range, 'Value': time_series})\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "df[\"MA_3\"] = df[\"Value\"].rolling(window=3, center=True).mean()\n",
    "df[\"MA_12\"] = df[\"Value\"].rolling(window=12, center=True).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df[\"Value\"], label=\"Original Time Series\", color=\"black\")\n",
    "plt.plot(df.index, df[\"MA_3\"], label=\"3-MA\", color=\"blue\")\n",
    "plt.plot(df.index, df[\"MA_12\"], label=\"12-MA\", color=\"red\")\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFZ-NEUT_d5Y"
   },
   "source": [
    "## Time Series Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dB7XW4tPqDie"
   },
   "source": [
    "Assuming an additive decomposition, a time series can be written as $Y = S + T + R$, where $Y$ is the data, $S$ is the seasonal component, $T$ is the trend-cycle component, and $R$ is the remainder component. Assuming a multiplicative decomposition, we could write $Y = S * T * R$.\n",
    "\n",
    "An additive decomposition is appropriate if the magnitude of seasonal/trend-cycle variations does not vary with the level of the time series. When the variations are proportional to the level of the time series, then a multiplicative decomposition is more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "3DeAKAk4_dfc",
    "outputId": "cfe6b6b8-adb2-49b8-a3ff-6418bc4b571c"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "date_range = pd.date_range(start=\"2020-01-01\", periods=1095, freq=\"D\")\n",
    "\n",
    "trend = np.linspace(50, 150, 1095)\n",
    "seasonality = 20 * np.sin(2 * np.pi * date_range.dayofyear / 365)\n",
    "noise = np.random.normal(0, 3, 1095)\n",
    "\n",
    "time_series = trend + seasonality + noise\n",
    "\n",
    "df = pd.DataFrame({\"Date\": date_range, \"Value\": time_series})\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "stl = STL(df[\"Value\"], period=365)\n",
    "decomposition = stl.fit()\n",
    "\n",
    "trend_stl = decomposition.trend\n",
    "seasonal_stl = decomposition.seasonal\n",
    "residual_stl = decomposition.resid\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(df.index, df[\"Value\"], label=\"Original\", color=\"black\")\n",
    "axes[0].set_title(\"Original Time Series\")\n",
    "\n",
    "axes[1].plot(df.index, trend_stl, label=\"Trend\", color=\"blue\")\n",
    "axes[1].set_title(\"Trend Component (STL)\")\n",
    "\n",
    "axes[2].plot(df.index, seasonal_stl, label=\"Seasonality\", color=\"green\")\n",
    "axes[2].set_title(\"Seasonal Component (STL)\")\n",
    "\n",
    "axes[3].plot(df.index, residual_stl, label=\"Residuals\", color=\"red\")\n",
    "axes[3].set_title(\"Remainder (Residuals)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEuZ_JsL3Ufl"
   },
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJ7qhQ-C9gjp"
   },
   "source": [
    "### Naive Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "date_range = pd.date_range(start=\"2015-01\", periods=60, freq=\"ME\")\n",
    "\n",
    "trend = np.linspace(50, 200, 60)\n",
    "\n",
    "seasonality = 15 * np.sin(2 * np.pi * date_range.month / 12)\n",
    "\n",
    "noise = np.random.normal(0, 8, 60)\n",
    "\n",
    "time_series = trend + seasonality + noise\n",
    "\n",
    "df = pd.DataFrame({\"Date\": date_range, \"Value\": time_series})\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "forecast_horizon = 12\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_horizon, freq=\"ME\")\n",
    "\n",
    "naive_forecast = np.full(forecast_horizon, df[\"Value\"].iloc[-1])\n",
    "mean_forecast = np.full(forecast_horizon, df[\"Value\"].mean())\n",
    "seasonal_naive_forecast = df[\"Value\"].iloc[-12:].values\n",
    "drift_slope = (df[\"Value\"].iloc[-1] - df[\"Value\"].iloc[0]) / (len(df) - 1)\n",
    "drift_forecast = df[\"Value\"].iloc[-1] + drift_slope * np.arange(1, forecast_horizon + 1)\n",
    "\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"Date\": future_dates,\n",
    "    \"Mean Forecast\": mean_forecast,\n",
    "    \"Naïve Forecast\": naive_forecast,\n",
    "    \"Seasonal Naïve Forecast\": np.tile(seasonal_naive_forecast, forecast_horizon // 12 + 1)[:forecast_horizon],\n",
    "    \"Drift Forecast\": drift_forecast\n",
    "}).set_index(\"Date\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot historical data\n",
    "plt.plot(df.index, df[\"Value\"], label=\"Original Series\", color=\"black\", marker=\"o\")\n",
    "\n",
    "# Plot forecasts\n",
    "plt.plot(forecast_df.index, forecast_df[\"Mean Forecast\"], label=\"Mean Forecast\", linestyle=\"--\", color=\"blue\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"Naïve Forecast\"], label=\"Naïve (Last Value) Forecast\", linestyle=\"--\", color=\"green\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"Seasonal Naïve Forecast\"], label=\"Seasonal Naïve Forecast\", linestyle=\"--\", color=\"orange\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"Drift Forecast\"], label=\"Drift Forecast\", linestyle=\"--\", color=\"red\")\n",
    "\n",
    "plt.axvline(df.index[-1], color=\"gray\", linestyle=\"--\", label=\"Forecast Start\")  # Vertical line at forecast start\n",
    "\n",
    "plt.title(\"Naïve Forecasting Methods\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT73cXoW9kvs"
   },
   "source": [
    "### Exponential smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods referred to as *Exponential smoothing* produce predictions that are weighted averages of past observations, with the weights decreasing exponentially as the observations get “older.”\n",
    "\n",
    "Simple Exponential Smoothing (SES): weighted average of the last N observations. Suitable for time series without trend and seasonality.\n",
    "\n",
    "Holt's method: an equation is added to model the trend as a weighted average of past observations of the trend estimate. The forecast grows/decreases linearly with the forecast horizon. This is why there is a variant that dampens the trend into the future, useful for long forecast horizons.\n",
    "\n",
    "Holt-Winters method: extension of Holt's method that also models the seasonal component. There are two variants: the additive method is appropriate when seasonal variations are somewhat constant over time, while the multiplicative method when the intensity of the seasonal variation changes over time.\n",
    "\n",
    "These are the best known Exponential smoothing methods, but in reality each combination of trend and seasonality can result in a different method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HJbMVD0F9kcL",
    "outputId": "fc79954b-fe5d-4c9d-eef3-1da65f76728d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, ExponentialSmoothing\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create date range\n",
    "date_range = pd.date_range(start=\"2015-01\", periods=60, freq=\"ME\")\n",
    "forecast_horizon = 24\n",
    "future_dates = pd.date_range(start=date_range[-1] + pd.DateOffset(months=1), periods=forecast_horizon, freq=\"ME\")\n",
    "\n",
    "# --- 1. Simple Exponential Smoothing (SES) ---\n",
    "ses_data = np.random.normal(50, 5, len(date_range))  # Constant mean + noise\n",
    "df_ses = pd.DataFrame({\"Date\": date_range, \"Value\": ses_data}).set_index(\"Date\")\n",
    "df_ses.index.freq = \"ME\"\n",
    "\n",
    "ses_model = SimpleExpSmoothing(df_ses[\"Value\"]).fit()\n",
    "ses_forecast = ses_model.forecast(forecast_horizon)\n",
    "\n",
    "# --- 2. Holt’s Linear Method ---\n",
    "trend = np.linspace(50, 500, len(date_range))  # Steeper linear trend\n",
    "holt_data = trend + np.random.normal(0, 10, len(date_range))  # Adding some noise\n",
    "df_holt = pd.DataFrame({\"Value\": holt_data}, index=date_range)\n",
    "df_holt.index.freq = \"ME\"\n",
    "\n",
    "holt_model = ExponentialSmoothing(df_holt[\"Value\"], trend=\"add\").fit()\n",
    "holt_forecast = holt_model.forecast(forecast_horizon)\n",
    "\n",
    "# --- 3. Holt-Winters (Trend + Seasonality) ---\n",
    "seasonality = 20 * np.sin(2 * np.pi * date_range.month / 12)\n",
    "holtwinters_data = trend + seasonality + np.random.normal(0, 5, len(date_range))\n",
    "df_holtwinters = pd.DataFrame({\"Date\": date_range, \"Value\": holtwinters_data}).set_index(\"Date\")\n",
    "df_holtwinters.index.freq = \"ME\"\n",
    "\n",
    "holtwinters_model = ExponentialSmoothing(df_holtwinters[\"Value\"], trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit()\n",
    "holtwinters_forecast = holtwinters_model.forecast(forecast_horizon)\n",
    "\n",
    "# --- Plot forecasts ---\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 12))\n",
    "\n",
    "# SES Plot\n",
    "axes[0].plot(df_ses.index, df_ses[\"Value\"], label=\"Original Series\", color=\"black\")\n",
    "axes[0].plot(future_dates, ses_forecast, label=\"SES Forecast\", linestyle=\"--\", color=\"blue\")\n",
    "axes[0].axvline(df_ses.index[-1], color=\"gray\", linestyle=\"--\", label=\"Forecast Start\")\n",
    "axes[0].set_title(\"Simple Exponential Smoothing (SES)\")\n",
    "axes[0].legend()\n",
    "axes[0].grid()\n",
    "\n",
    "# Holt’s Linear Trend vs. Holt Damped Trend\n",
    "axes[1].plot(df_holt.index, df_holt[\"Value\"], label=\"Original Series\", color=\"black\")\n",
    "axes[1].plot(future_dates, holt_forecast, label=\"Holt’s Forecast (Linear Trend)\", linestyle=\"--\", color=\"red\")\n",
    "axes[1].axvline(df_holt.index[-1], color=\"gray\", linestyle=\"--\", label=\"Forecast Start\")\n",
    "axes[1].set_title(\"Holt’s Linear Trend\")\n",
    "axes[1].legend()\n",
    "axes[1].grid()\n",
    "\n",
    "# Holt-Winters Plot\n",
    "axes[2].plot(df_holtwinters.index, df_holtwinters[\"Value\"], label=\"Original Series\", color=\"black\")\n",
    "axes[2].plot(future_dates, holtwinters_forecast, label=\"Holt-Winters Forecast\", linestyle=\"--\", color=\"green\")\n",
    "axes[2].axvline(df_holtwinters.index[-1], color=\"gray\", linestyle=\"--\", label=\"Forecast Start\")\n",
    "axes[2].set_title(\"Holt-Winters (Trend + Seasonality)\")\n",
    "axes[2].legend()\n",
    "axes[2].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6bem475OJnF"
   },
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stationary time series has statistical properties that do not depend on when the series is observed. In general, a time series is stationary if it has no predictable long-term patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a common date range\n",
    "date_range = pd.date_range(start=\"2015-01\", periods=100, freq=\"ME\")\n",
    "\n",
    "# --- 1. Time Series with a Change in Level ---\n",
    "level_change_data = np.concatenate([\n",
    "    np.random.normal(50, 5, 50),  # First half around 50\n",
    "    np.random.normal(80, 5, 50)   # Second half shifts to around 80\n",
    "])\n",
    "df_level_change = pd.DataFrame({\"Value\": level_change_data}, index=date_range)\n",
    "\n",
    "# --- 2. Time Series with Increasing Variance ---\n",
    "constant_mean = 50  # Fixed mean value\n",
    "increasing_variance_data = constant_mean + np.random.normal(0, np.linspace(2, 20, len(date_range)))  # Growing noise\n",
    "# Convert to DataFrame\n",
    "df_increasing_variance = pd.DataFrame({\"Value\": increasing_variance_data}, index=date_range)\n",
    "\n",
    "# --- 3. Stationary Series - White Noise ---\n",
    "white_noise = np.random.normal(50, 5, len(date_range))\n",
    "df_white_noise = pd.DataFrame({\"Value\": white_noise}, index=date_range)\n",
    "\n",
    "# --- 4. Stationary Series - AR(1) Process ---\n",
    "phi = 0.6  # Autoregressive coefficient (ensuring stationarity)\n",
    "ar_process = [0]  # Start with an initial value\n",
    "for t in range(1, len(date_range)):\n",
    "    ar_process.append(phi * ar_process[t-1] + np.random.normal(0, 5))  # AR(1) formula\n",
    "df_ar1 = pd.DataFrame({\"Value\": ar_process}, index=date_range)\n",
    "\n",
    "# --- Plot all cases ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Change in Level\n",
    "axes[0, 0].plot(df_level_change, label=\"\", color=\"blue\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid()\n",
    "\n",
    "# Increasing Variance\n",
    "axes[0, 1].plot(df_increasing_variance, label=\"\", color=\"green\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid()\n",
    "\n",
    "# White Noise (Stationary)\n",
    "axes[1, 0].plot(df_white_noise, label=\"\", color=\"orange\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid()\n",
    "\n",
    "# AR(1) Process (Stationary)\n",
    "axes[1, 1].plot(df_ar1, label=\"\", color=\"purple\")\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDjuU8moFUtf"
   },
   "source": [
    "A non-stationary time series can be made stationary by “differentiating” it; that is, by calculating the differences between consecutive observations: $$y_t - y_{t-1}$$\n",
    "\n",
    "Just as a logarithmic transformation can help stabilize the variance of a time series, differentiating a time series can help stabilize its mean, because it can eliminate (or at least reduce) trend and seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=\"2023-01-01\", periods=12, freq=\"ME\")\n",
    "sales = np.random.randint(100, 500, size=len(date_range))\n",
    "\n",
    "df = pd.DataFrame({\"date\": date_range, \"sales\": sales}).set_index(\"date\")\n",
    "df[\"sales_change\"] = df[\"sales\"].diff()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the differenced series is a white noise: $$y_t - y_{t-1} = \\epsilon_t$$ then the original series is a \"random walk\": $$y_t = y_{t-1} + \\epsilon_t$$\n",
    "\n",
    "Random walk models are widely used for non-stationary data, particularly financial and economic data.\n",
    "\n",
    "The random walk with drift allows a non-zero mean: $$y_t = c + y_{t-1} + \\epsilon_t$$\n",
    "\n",
    "The value of c is the average of the variations between consecutive observations: if it is positive, the series will tend upward (upward drift); if it is negative, downward (downward drift)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the differenced series is still non-stationary, so it may be necessary to differentiate a second time to obtain a stationary series. One differentiation may be a seasonal difference, which consists of subtracting from a value the previous value from the same seasonal period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a time range\n",
    "date_range = pd.date_range(start=\"2010-01\", periods=100, freq=\"ME\")\n",
    "\n",
    "# --- 1. Non-Stationary Series (Trend) ---\n",
    "trend = np.linspace(50, 150, len(date_range))  # Increasing trend\n",
    "trend_data = trend + np.random.normal(0, 5, len(date_range))  # Add noise\n",
    "df_trend = pd.DataFrame({\"Value\": trend_data}, index=date_range)\n",
    "\n",
    "# First-order differencing\n",
    "df_trend_diff = df_trend.diff().dropna()\n",
    "\n",
    "# --- 2. Non-Stationary Series (Seasonality) ---\n",
    "seasonality = 10 * np.sin(2 * np.pi * date_range.month / 12)  # Seasonal pattern\n",
    "seasonal_data = 50 + seasonality + np.random.normal(0, 3, len(date_range))  # Add noise\n",
    "df_seasonal = pd.DataFrame({\"Value\": seasonal_data}, index=date_range)\n",
    "\n",
    "# Seasonal differencing (12-month lag)\n",
    "df_seasonal_diff = df_seasonal.diff(periods=12).dropna()\n",
    "\n",
    "# --- Plot the Results ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Original trend series\n",
    "axes[0, 0].plot(df_trend, label=\"Original Trend Series\", color=\"black\")\n",
    "axes[0, 0].set_title(\"Non-Stationary Time Series (Trend)\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid()\n",
    "\n",
    "# Differenced trend series\n",
    "axes[0, 1].plot(df_trend_diff, label=\"First Difference (Trend Removed)\", color=\"blue\")\n",
    "axes[0, 1].set_title(\"First-Order Differencing (Stationary)\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid()\n",
    "\n",
    "# Original seasonal series\n",
    "axes[1, 0].plot(df_seasonal, label=\"Original Seasonal Series\", color=\"black\")\n",
    "axes[1, 0].set_title(\"Non-Stationary Time Series (Seasonality)\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid()\n",
    "\n",
    "# Seasonal differencing\n",
    "axes[1, 1].plot(df_seasonal_diff, label=\"Seasonally Differenced (Seasonality Removed)\", color=\"blue\")\n",
    "axes[1, 1].set_title(\"Seasonal Differencing (Lag=12)\")\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to determine more objectively whether differentiation is needed is to use a unit root test, such as KPSS, where the null hypothesis is that the data are stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationary time series can be modeled by ARMA models, formed by the combination of an autoregressive (AR) component and a moving average (MA) component. Autoregressive models predict using a linear combination of past values, while moving-average models using a linear combination of past errors (moving-average models should not be confused with the concept of moving average, which is used to “smooth” a time series).\n",
    "\n",
    "The ARIMA and SARIMA models are generalizations of the ARMA models to model non-stationary and seasonal time series, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pmdarima==2.0.4 numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Generate a Synthetic Time Series ---\n",
    "np.random.seed(42)\n",
    "date_range = pd.date_range(start=\"2010-01\", periods=100, freq=\"ME\")\n",
    "trend = np.linspace(50, 150, len(date_range))  # Upward trend\n",
    "seasonality = 10 * np.sin(2 * np.pi * date_range.month / 12)  # Annual seasonality\n",
    "noise = np.random.normal(0, 5, len(date_range))  # Random noise\n",
    "data = trend + seasonality + noise\n",
    "\n",
    "df = pd.DataFrame({\"Date\": date_range, \"Value\": data}).set_index(\"Date\")\n",
    "\n",
    "# --- 2. Fit an ARIMA Model Using auto_arima ---\n",
    "model = pm.auto_arima(df[\"Value\"], \n",
    "                      seasonal=True,  # Enable seasonal ARIMA\n",
    "                      m=12,           # Seasonality of 12 months\n",
    "                      stepwise=True,  # Efficient search\n",
    "                      suppress_warnings=True)\n",
    "\n",
    "# --- 3. Forecast Future Values ---\n",
    "forecast_horizon = 24\n",
    "forecast, conf_int = model.predict(n_periods=forecast_horizon, return_conf_int=True)\n",
    "\n",
    "# --- 4. Create Future Date Range ---\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.DateOffset(months=1), periods=forecast_horizon, freq=\"M\")\n",
    "\n",
    "# --- 5. Plot the Results ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index, df[\"Value\"], label=\"Original Series\", color=\"black\")\n",
    "plt.plot(future_dates, forecast, label=\"Forecast\", linestyle=\"--\", color=\"blue\")\n",
    "plt.fill_between(future_dates, conf_int[:, 0], conf_int[:, 1], color=\"blue\", alpha=0.2, label=\"95% Prediction Interval\")\n",
    "plt.axvline(df.index[-1], color=\"gray\", linestyle=\"--\", label=\"Forecast Start\")\n",
    "plt.legend()\n",
    "plt.title(\"ARIMA Forecast Using pmdarima\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Given the following dataframe of sales transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"date\": [\n",
    "        \"2023-05-01\", \"2023-05-02\",\n",
    "        \"2023-05-05\", \"2023-05-07\",\n",
    "        \"2023-05-10\", \"2023-05-15\",\n",
    "        \"2023-05-20\", \"2023-05-25\",\n",
    "        \"2023-05-30\", \"2023-05-31\"\n",
    "    ],\n",
    "    \"sales_amount\": [100, 150, 200, 130, 180, 250, 300, 220, 270, 310]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a new column with the number of days since the last sales\n",
    "- add missing dates, filling missing values for sales_amount with 0\n",
    "- create a new column with the sale amount of 7 days before\n",
    "- create a new column with the mean amount of sales for the previous 7 days\n",
    "- convert the frequency to weekly, summing the sales for each week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Given the following sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "date_range = pd.date_range(start=\"2023-01-01\", periods=180, freq=\"D\")\n",
    "values = np.array([200, 220, 250, 230, 240, 260, 280], dtype=float)\n",
    "sales = np.tile(values, len(date_range) // 7 + 1)[:len(date_range)]\n",
    "sales += np.random.normal(0, 10, len(sales))\n",
    "df = pd.DataFrame({\"date\": date_range, \"sales\": sales})\n",
    "df.set_index(\"date\", inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x=df.index, y=\"sales\")\n",
    "plt.title(\"Daily Sales\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the appropriate Exponential Smoothing model to forecast sales for the following 7 days.<br>\n",
    "Bonus: plot the historical data and the generated forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
