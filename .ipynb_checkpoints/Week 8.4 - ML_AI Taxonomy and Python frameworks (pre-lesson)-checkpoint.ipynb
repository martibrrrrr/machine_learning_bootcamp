{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning, AI, and GenAI Taxonomy and MLOps Frameworks\n",
    "\n",
    "## 1. Foundational Concepts and Terminology\n",
    "\n",
    "### Core Machine Learning Concepts\n",
    "\n",
    "- **Machine Learning (ML)**: Field of study that gives computers the ability to learn without being explicitly programmed\n",
    "- **Algorithm**: Step-by-step procedure for solving a problem or accomplishing a task\n",
    "- **Model**: Mathematical representation learned from data to make predictions or decisions\n",
    "- **Feature**: Individual measurable property or characteristic used as input for a machine learning algorithm\n",
    "- **Label/Target**: The output value that a model is trained to predict\n",
    "- **Training**: Process of teaching a model using labeled data\n",
    "- **Inference**: Process of using a trained model to make predictions\n",
    "- **Supervised Learning**: Training a model on labeled data\n",
    "- **Unsupervised Learning**: Finding patterns in unlabeled data\n",
    "- **Semi-Supervised Learning**: Training with a combination of labeled and unlabeled data\n",
    "- **Reinforcement Learning**: Learning through interaction with an environment using rewards and penalties\n",
    "- **Transfer Learning**: Applying knowledge from one trained model to a different but related task\n",
    "- **Fine-tuning**: Further training a pre-trained model on a specific dataset for a specific task\n",
    "- **Overfitting**: When a model learns the training data too well, including noise and outliers\n",
    "- **Underfitting**: When a model is too simple to capture the underlying patterns in the data\n",
    "- **Bias**: Error due to overly simplistic assumptions in the model\n",
    "- **Variance**: Error due to too much complexity in the model\n",
    "- **Hyperparameter**: Parameter set before training begins (not learned from data)\n",
    "- **Parameter**: Value learned during model training from data\n",
    "\n",
    "### Artificial Intelligence Concepts\n",
    "\n",
    "- **Artificial Intelligence (AI)**: Broad field encompassing machine learning and systems designed to mimic human intelligence\n",
    "- **Narrow/Weak AI**: AI systems designed for specific tasks (all current AI systems)\n",
    "- **General/Strong AI**: Hypothetical AI with human-like general intelligence across domains\n",
    "- **Artificial General Intelligence (AGI)**: AI with the ability to understand, learn, and apply knowledge across different domains\n",
    "- **Superintelligence**: Hypothetical AI that surpasses human intelligence\n",
    "- **Expert System**: Rule-based AI system that emulates human expertise in a specific domain\n",
    "- **Cognitive Computing**: AI systems that attempt to simulate human thought processes\n",
    "- **Computer Vision**: AI field focused on enabling computers to see, identify and process images\n",
    "- **Natural Language Processing (NLP)**: AI field focused on enabling computers to understand and generate human language\n",
    "\n",
    "### Generative AI Concepts\n",
    "\n",
    "- **Generative AI (GenAI)**: AI systems that can generate new content (text, images, audio, video, etc.)\n",
    "- **Generative Model**: Model that can generate new data instances similar to the training data\n",
    "- **Large Language Model (LLM)**: Neural network trained on vast text data capable of generating human-like text\n",
    "- **Foundation Model**: Large model trained on broad data that can be adapted to many downstream tasks\n",
    "- **Diffusion Model**: Type of generative model that gradually adds and then removes noise to generate data\n",
    "- **Prompt**: Input text that directs or instructs an AI system to generate specific outputs\n",
    "- **Prompt Engineering**: Practice of designing effective prompts to get desired outputs from AI systems\n",
    "- **In-context Learning**: Ability of models to learn from examples provided in the prompt\n",
    "- **Retrieval-Augmented Generation (RAG)**: Technique that enhances generation by retrieving relevant information\n",
    "- **Hallucination**: When AI generates factually incorrect or nonexistent information\n",
    "- **Multimodal Model**: Model capable of processing and generating multiple types of data (text, image, audio)\n",
    "- **Text-to-Image**: AI models that generate images based on text descriptions\n",
    "- **Text-to-Audio/Speech**: AI models that convert text to spoken audio\n",
    "- **Text-to-Video**: AI models that generate video content based on text descriptions\n",
    "\n",
    "### Neural Network Concepts\n",
    "\n",
    "- **Neural Network**: Computing system inspired by biological neural networks\n",
    "- **Deep Learning**: Subset of ML using neural networks with multiple layers\n",
    "- **Neuron/Node**: Basic computational unit in a neural network\n",
    "- **Weight**: Parameter associated with connections between neurons\n",
    "- **Activation Function**: Function determining the output of a neuron\n",
    "- **Backpropagation**: Algorithm for updating weights based on error gradient\n",
    "- **Gradient Descent**: Optimization algorithm for minimizing error\n",
    "- **Epoch**: One complete pass through the entire training dataset\n",
    "- **Batch**: Subset of training data processed together\n",
    "- **Layer**: Group of neurons processing input and producing output\n",
    "- **Hidden Layer**: Layer between input and output layers\n",
    "- **Convolutional Neural Network (CNN)**: Neural network specialized for image processing\n",
    "- **Recurrent Neural Network (RNN)**: Neural network with feedback connections for sequential data\n",
    "- **Transformer**: Neural network architecture using self-attention mechanisms\n",
    "- **Attention Mechanism**: Technique allowing models to focus on relevant parts of input\n",
    "- **Encoder-Decoder**: Architecture consisting of modules for encoding input and decoding output\n",
    "- **Embedding**: Dense vector representation of discrete variables\n",
    "- **Tokenization**: Process of converting text into discrete tokens for processing\n",
    "\n",
    "### Causal AI Concepts\n",
    "\n",
    "- **Causal AI**: AI systems designed to understand and model cause-and-effect relationships rather than just statistical correlations\n",
    "- **Causality**: Study of how one event influences the occurrence of another event\n",
    "- **Causal Inference**: Process of determining cause-and-effect relationships from data\n",
    "- **Counterfactual**: Hypothetical scenario describing what would have happened under different conditions\n",
    "- **Structural Causal Model (SCM)**: Mathematical framework for representing causal relationships\n",
    "- **Causal Graph/Diagram**: Visual representation of causal relationships between variables\n",
    "- **Directed Acyclic Graph (DAG)**: Graph with directed edges and no cycles, used to represent causal relationships\n",
    "- **Confounding Variable**: Factor that influences both the cause and effect, potentially leading to spurious correlations\n",
    "- **Treatment Effect**: Causal effect of an intervention or treatment on an outcome\n",
    "- **Average Treatment Effect (ATE)**: Average effect of a treatment across an entire population\n",
    "- **Do-Calculus**: Set of rules for manipulating causal graphs to identify causal effects\n",
    "- **Instrumental Variable**: Variable used to estimate causal relationships when confounding is present\n",
    "- **Propensity Score**: Probability of receiving treatment based on observed covariates\n",
    "- **Rubin Causal Model**: Framework for causal inference based on potential outcomes\n",
    "- **Granger Causality**: Statistical concept where past values of one time series predict another\n",
    "- **Natural Experiment**: Observational study where treatment assignment resembles random assignment\n",
    "- **Randomized Controlled Trial (RCT)**: Experimental design where subjects are randomly assigned to treatment groups\n",
    "- **Causal Discovery**: Automated identification of causal relationships from observational data\n",
    "\n",
    "## 2. MLOps Terminology and Concepts\n",
    "\n",
    "### MLOps General Concepts\n",
    "\n",
    "- **MLOps**: Practices combining Machine Learning, DevOps, and Data Engineering\n",
    "- **ML Lifecycle**: End-to-end process of developing, deploying, and maintaining ML models\n",
    "- **Model Registry**: Central repository for storing and versioning models\n",
    "- **Feature Store**: System for storing, managing, and serving features\n",
    "- **Model Versioning**: Tracking different iterations of models\n",
    "- **Experiment Tracking**: Recording parameters, metrics, and artifacts during model development\n",
    "- **A/B Testing**: Comparing performance of different models or features\n",
    "- **Model Monitoring**: Tracking model performance in production\n",
    "- **Drift Detection**: Identifying changes in data or model performance over time\n",
    "- **Concept Drift**: Change in the statistical properties of the target variable\n",
    "- **Data Drift**: Change in the statistical properties of the input data\n",
    "- **CI/CD for ML**: Continuous Integration/Continuous Deployment adapted for ML workflows\n",
    "- **Model Governance**: Policies and procedures for managing models throughout their lifecycle\n",
    "- **Model Explainability**: Making model decisions understandable to humans\n",
    "- **ML Metadata**: Information about datasets, models, and experiments\n",
    "\n",
    "### Data Engineering Concepts\n",
    "\n",
    "- **Data Pipeline**: Series of processing steps to transform raw data\n",
    "- **ETL (Extract, Transform, Load)**: Process of collecting, transforming, and storing data\n",
    "- **Data Warehouse**: System for storing and analyzing structured data\n",
    "- **Data Lake**: Repository for storing structured and unstructured data\n",
    "- **Data Lakehouse**: Combines elements of data warehouses and data lakes\n",
    "- **Data Catalog**: Inventory of available data assets\n",
    "- **Data Lineage**: Documentation of data's origins and transformations\n",
    "- **Data Version Control**: Tracking changes to datasets over time\n",
    "- **Data Quality**: Measures of data's fitness for use\n",
    "- **Data Validation**: Checking data against defined rules and constraints\n",
    "\n",
    "### Model Deployment Concepts\n",
    "\n",
    "- **Model Serving**: Making models available for inference\n",
    "- **Inference API**: Interface for interacting with deployed models\n",
    "- **Model Containerization**: Packaging models with dependencies\n",
    "- **Orchestration**: Managing and automating workflows\n",
    "- **Scaling**: Adjusting resources based on demand\n",
    "- **Microservices**: Architecture using small, independent services\n",
    "- **Edge Deployment**: Running models on edge devices\n",
    "- **Model Compression**: Reducing model size for efficient deployment\n",
    "- **Quantization**: Reducing precision of model parameters\n",
    "- **Pruning**: Removing unnecessary connections in neural networks\n",
    "- **Knowledge Distillation**: Training a smaller model to mimic a larger one\n",
    "\n",
    "## 3. Python Frameworks for MLOps\n",
    "\n",
    "### Data Processing and Engineering\n",
    "\n",
    "- **Pandas**: Data manipulation and analysis\n",
    "- **NumPy**: Numerical computing with arrays and matrices\n",
    "- **Polars**: Fast DataFrame library (alternative to Pandas)\n",
    "- **Dask**: Parallel computing with larger-than-memory datasets\n",
    "- **PySpark**: Python API for Apache Spark (distributed computing)\n",
    "- **Great Expectations**: Data validation and documentation\n",
    "- **Delta Lake**: Storage layer for lakehouse architecture\n",
    "\n",
    "### Machine Learning and Model Training\n",
    "\n",
    "- **Scikit-learn**: General-purpose ML library\n",
    "- **PyTorch**: Deep learning framework\n",
    "- **TensorFlow**: Deep learning framework\n",
    "- **JAX**: High-performance numerical computing\n",
    "- **Keras**: High-level neural networks API\n",
    "- **XGBoost**: Gradient boosting framework\n",
    "- **LightGBM**: Gradient boosting framework\n",
    "- **CatBoost**: Gradient boosting framework\n",
    "- **Hugging Face Transformers**: Pre-trained models for NLP and computer vision\n",
    "- **Fastai**: High-level deep learning library\n",
    "- **PyTorch Lightning**: Lightweight PyTorch wrapper for research\n",
    "- **Langchain**: Framework for developing LLM applications\n",
    "\n",
    "### Causal Inference and Causal AI Frameworks\n",
    "\n",
    "- **DoWhy**: End-to-end library for causal inference\n",
    "- **EconML**: Library for estimating heterogeneous treatment effects\n",
    "- **CausalML**: Suite of uplift modeling and causal inference methods\n",
    "- **CausalNex**: Library for causal reasoning and Bayesian Networks\n",
    "- **CausalImpact**: Inferring causal effects in time series\n",
    "- **PyMC**: Probabilistic programming for Bayesian modeling\n",
    "- **CausalPy**: Tools for causal inference and causal discovery\n",
    "Ã¬- **WhyNot**: Framework for causal counterfactual analysis\n",
    "\n",
    "### Experiment Tracking and Model Development\n",
    "\n",
    "- **MLflow**: Platform for ML lifecycle management\n",
    "- **Weights & Biases**: Experiment tracking and visualization\n",
    "- **TensorBoard**: Visualization toolkit for TensorFlow\n",
    "- **Optuna**: Hyperparameter optimization framework\n",
    "- **Ray Tune**: Hyperparameter tuning at scale\n",
    "\n",
    "### Model Deployment and Serving\n",
    "\n",
    "- **FastAPI**: Web framework for building APIs\n",
    "- **Flask**: Lightweight web framework\n",
    "- **TorchServe**: Serving framework for PyTorch models\n",
    "- **TensorFlow Serving**: Serving system for TensorFlow models\n",
    "- **Seldon Core**: Platform for deploying ML models on Kubernetes\n",
    "- **Ray Serve**: Framework for scalable model serving\n",
    "- **Gradio**: Library for creating UIs for ML models\n",
    "- **Streamlit**: App framework for ML and data science\n",
    "\n",
    "### MLOps Orchestration and Pipelines\n",
    "\n",
    "- **Airflow**: Platform for orchestrating workflows\n",
    "- **Prefect**: Workflow management system\n",
    "- **Kubeflow**: ML toolkit for Kubernetes\n",
    "- **Luigi**: Pipeline management framework\n",
    "- **Kedro**: Development workflow framework\n",
    "\n",
    "### Model Explainability and Interpretability\n",
    "\n",
    "- **SHAP (SHapley Additive exPlanations)**: Game theoretic approach to explain model output\n",
    "- **LIME (Local Interpretable Model-agnostic Explanations)**: Explaining predictions of any classifier\n",
    "- **InterpretML**: Package for training interpretable models and explaining blackbox systems\n",
    "- **ELI5**: Library for debugging/inspecting machine learning classifiers\n",
    "\n",
    "### LLM and GenAI Frameworks\n",
    "\n",
    "- **LangChain**: Framework for developing applications with LLMs\n",
    "- **LlamaIndex**: Data framework for LLM applications\n",
    "- **Haystack**: Framework for building search systems and question answering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
