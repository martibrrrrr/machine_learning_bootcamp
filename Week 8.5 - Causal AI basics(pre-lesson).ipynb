{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Causal AI Concepts\n",
    "\n",
    "This notebook introduces foundational concepts in causal AI with simple examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correlation vs. Causation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between ice cream sales and drownings: 0.69\n",
      "Despite high correlation, ice cream doesn't cause drownings - temperature affects both!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate synthetic data where ice cream sales and drowning incidents are both caused by temperature\n",
    "np.random.seed(42)\n",
    "n = 100\n",
    "temperature = np.random.normal(25, 5, n)  # Mean 25°C, std 5°C\n",
    "ice_cream_sales = 100 + 20 * temperature + np.random.normal(0, 50, n)  # Affected by temperature\n",
    "drownings = 5 + 0.8 * temperature + np.random.normal(0, 3, n)  # Also affected by temperature\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Temperature': temperature,\n",
    "    'Ice_Cream_Sales': ice_cream_sales,\n",
    "    'Drownings': drownings\n",
    "})\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = data['Ice_Cream_Sales'].corr(data['Drownings'])\n",
    "print(f\"Correlation between ice cream sales and drownings: {correlation:.2f}\")\n",
    "print(\"Despite high correlation, ice cream doesn't cause drownings - temperature affects both!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Causal Graphs (Directed Acyclic Graphs - DAGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a simple causal graph\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([\n",
    "    ('Temperature', 'Ice_Cream_Sales'),\n",
    "    ('Temperature', 'Drownings'),\n",
    "])\n",
    "\n",
    "# Uncomment to display graph (requires graphviz)\n",
    "# import matplotlib.pyplot as plt\n",
    "# pos = nx.spring_layout(G)\n",
    "# nx.draw(G, pos, with_labels=True, node_color='lightblue', node_size=2000, arrowsize=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interventions (do-calculus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average drownings when observing high ice cream sales: 28.58\n",
      "Average drownings when intervening on ice cream sales: 24.78\n",
      "The intervention shows that ice cream sales don't affect drownings!\n"
     ]
    }
   ],
   "source": [
    "# Simulating an intervention (do-operator)\n",
    "def observe_ice_cream(sales_level):\n",
    "    \"\"\"Filter data based on observed ice cream sales\"\"\"\n",
    "    return data[data['Ice_Cream_Sales'] > sales_level]\n",
    "\n",
    "def do_ice_cream(sales_level):\n",
    "    \"\"\"Simulate intervention where we set ice cream sales to a specific level\"\"\"\n",
    "    # In a do-intervention, we break the link from Temperature to Ice_Cream_Sales\n",
    "    # This means drownings will still be determined by temperature, not by ice cream sales\n",
    "    \n",
    "    # Create new dataframe with same temperature and drowning values\n",
    "    intervened_data = data.copy()\n",
    "    # Set all ice cream sales to the intervention level\n",
    "    intervened_data['Ice_Cream_Sales'] = sales_level\n",
    "    return intervened_data\n",
    "\n",
    "# Compare observation vs. intervention\n",
    "high_observed = observe_ice_cream(600)\n",
    "high_intervened = do_ice_cream(600)\n",
    "\n",
    "print(f\"Average drownings when observing high ice cream sales: {high_observed['Drownings'].mean():.2f}\")\n",
    "print(f\"Average drownings when intervening on ice cream sales: {high_intervened['Drownings'].mean():.2f}\")\n",
    "print(\"The intervention shows that ice cream sales don't affect drownings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original scenario: 34.3°C with 33.1 drownings\n",
      "Counterfactual: If temperature was 24.3°C, drownings would be 25.1\n",
      "Lives potentially saved: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Counterfactual example: What if we had controlled the temperature?\n",
    "def counterfactual_temperature_control(row, target_temp):\n",
    "    \"\"\"Generate counterfactual: What if temperature had been 'target_temp' instead?\"\"\"\n",
    "    # Calculate how ice cream sales and drownings would change\n",
    "    temp_diff = target_temp - row['Temperature']\n",
    "    \n",
    "    # Compute counterfactual values\n",
    "    cf_ice_cream = row['Ice_Cream_Sales'] + 20 * temp_diff  # Using our known causal model\n",
    "    cf_drownings = row['Drownings'] + 0.8 * temp_diff       # Using our known causal model\n",
    "    \n",
    "    return pd.Series({\n",
    "        'Original_Temp': row['Temperature'],\n",
    "        'Counterfactual_Temp': target_temp,\n",
    "        'Original_Drownings': row['Drownings'],\n",
    "        'Counterfactual_Drownings': cf_drownings\n",
    "    })\n",
    "\n",
    "# Pick a specific day and ask: What if temperature had been lower?\n",
    "hot_day = data.iloc[data['Temperature'].argmax()]\n",
    "counterfactual = counterfactual_temperature_control(hot_day, hot_day['Temperature'] - 10)\n",
    "\n",
    "print(f\"Original scenario: {counterfactual['Original_Temp']:.1f}°C with {counterfactual['Original_Drownings']:.1f} drownings\")\n",
    "print(f\"Counterfactual: If temperature was {counterfactual['Counterfactual_Temp']:.1f}°C, drownings would be {counterfactual['Counterfactual_Drownings']:.1f}\")\n",
    "print(f\"Lives potentially saved: {counterfactual['Original_Drownings'] - counterfactual['Counterfactual_Drownings']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Propensity Score Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive estimate of treatment effect: 0.17\n",
      "This is biased because sicker patients tend to get treatment\n",
      "Estimated treatment effect using propensity matching: 3.97\n",
      "With better matching and larger samples, this would approach the true effect of 5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/j8j7r8m13t1bxnb4dzss62p80000gq/T/ipykernel_15085/2729809498.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "/var/folders/wg/j8j7r8m13t1bxnb4dzss62p80000gq/T/ipykernel_15085/2729809498.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "/var/folders/wg/j8j7r8m13t1bxnb4dzss62p80000gq/T/ipykernel_15085/2729809498.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "/var/folders/wg/j8j7r8m13t1bxnb4dzss62p80000gq/T/ipykernel_15085/2729809498.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
      "/var/folders/wg/j8j7r8m13t1bxnb4dzss62p80000gq/T/ipykernel_15085/2729809498.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n"
     ]
    }
   ],
   "source": [
    "# Generate treatment effect data\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Covariates\n",
    "age = np.random.normal(40, 10, n)\n",
    "severity = np.random.normal(5, 2, n)\n",
    "\n",
    "# Treatment assignment (influenced by covariates)\n",
    "# Older patients and more severe cases more likely to get treatment\n",
    "propensity = 1 / (1 + np.exp(-(age - 40) / 10 - severity + 2))\n",
    "treatment = np.random.binomial(1, propensity)\n",
    "\n",
    "# Outcome (true treatment effect is +5)\n",
    "# Severity negatively affects outcome, age has a small effect\n",
    "outcome = 70 - 2 * severity + 0.1 * age + 5 * treatment + np.random.normal(0, 3, n)\n",
    "\n",
    "treatment_data = pd.DataFrame({\n",
    "    'Age': age,\n",
    "    'Severity': severity,\n",
    "    'Treatment': treatment,\n",
    "    'Outcome': outcome,\n",
    "    'Propensity': propensity\n",
    "})\n",
    "\n",
    "# Naive estimate (biased due to confounding)\n",
    "treated = treatment_data[treatment_data['Treatment'] == 1]['Outcome'].mean()\n",
    "untreated = treatment_data[treatment_data['Treatment'] == 0]['Outcome'].mean()\n",
    "print(f\"Naive estimate of treatment effect: {treated - untreated:.2f}\")\n",
    "print(\"This is biased because sicker patients tend to get treatment\")\n",
    "\n",
    "# Simple propensity score matching\n",
    "def match_patient(patient, treatment_group, n_matches=1):\n",
    "    \"\"\"Find matching patients from the opposite treatment group\"\"\"\n",
    "    opposite_group = treatment_data[treatment_data['Treatment'] != treatment_group]\n",
    "    \n",
    "    # Calculate propensity score distance\n",
    "    opposite_group['distance'] = abs(opposite_group['Propensity'] - patient['Propensity'])\n",
    "    \n",
    "    # Return n closest matches\n",
    "    return opposite_group.nsmallest(n_matches, 'distance')\n",
    "\n",
    "# Sample a few treated patients and find their matches\n",
    "sample_treated = treatment_data[treatment_data['Treatment'] == 1].sample(5)\n",
    "matched_outcomes = []\n",
    "\n",
    "for _, patient in sample_treated.iterrows():\n",
    "    matches = match_patient(patient, 1, n_matches=1)\n",
    "    effect = patient['Outcome'] - matches['Outcome'].values[0]\n",
    "    matched_outcomes.append(effect)\n",
    "\n",
    "print(f\"Estimated treatment effect using propensity matching: {np.mean(matched_outcomes):.2f}\")\n",
    "print(\"With better matching and larger samples, this would approach the true effect of 5.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Instrumental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive regression (biased due to omitted ability variable):\n",
      "Estimated return to education: $3242.61 per year\n",
      "\n",
      "Instrumental variables estimate (using distance to college):\n",
      "Estimated return to education: $2689.58 per year\n",
      "This is closer to the true causal effect of $3000 per year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/j8j7r8m13t1bxnb4dzss62p80000gq/T/ipykernel_15085/1594029090.py:32: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"Estimated return to education: ${model.params[1]:.2f} per year\")\n",
      "/var/folders/wg/j8j7r8m13t1bxnb4dzss62p80000gq/T/ipykernel_15085/1594029090.py:45: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f\"Estimated return to education: ${second_stage.params[1]:.2f} per year\")\n"
     ]
    }
   ],
   "source": [
    "# Example: Effect of education on earnings using distance to college as instrument\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "# Unobserved confounder: ability\n",
    "ability = np.random.normal(100, 15, n)\n",
    "\n",
    "# Instrument: distance to nearest college (km)\n",
    "# Not affected by ability or other confounders\n",
    "distance_to_college = np.random.gamma(2, 20, n)\n",
    "\n",
    "# Education years (affected by distance and ability)\n",
    "education = 12 + 5 - 0.05 * distance_to_college + 0.04 * ability + np.random.normal(0, 1, n)\n",
    "education = np.maximum(education, 8)  # Minimum 8 years of education\n",
    "\n",
    "# Earnings (affected by education and ability)\n",
    "earnings = 20000 + 3000 * (education - 12) + 200 * ability + np.random.normal(0, 5000, n)\n",
    "\n",
    "iv_data = pd.DataFrame({\n",
    "    'Distance_to_College': distance_to_college,\n",
    "    'Education_Years': education,\n",
    "    'Earnings': earnings,\n",
    "    'Ability': ability  # Would be unobserved in real data\n",
    "})\n",
    "\n",
    "# Naive regression (biased due to unobserved confounder)\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(iv_data['Education_Years'])\n",
    "model = sm.OLS(iv_data['Earnings'], X).fit()\n",
    "print(\"Naive regression (biased due to omitted ability variable):\")\n",
    "print(f\"Estimated return to education: ${model.params[1]:.2f} per year\")\n",
    "\n",
    "# Two-stage least squares (2SLS) for instrumental variables\n",
    "# First stage: Regress education on instrument\n",
    "X_first = sm.add_constant(iv_data['Distance_to_College'])\n",
    "first_stage = sm.OLS(iv_data['Education_Years'], X_first).fit()\n",
    "iv_data['Predicted_Education'] = first_stage.predict(X_first)\n",
    "\n",
    "# Second stage: Regress earnings on predicted education\n",
    "X_second = sm.add_constant(iv_data['Predicted_Education'])\n",
    "second_stage = sm.OLS(iv_data['Earnings'], X_second).fit()\n",
    "\n",
    "print(\"\\nInstrumental variables estimate (using distance to college):\")\n",
    "print(f\"Estimated return to education: ${second_stage.params[1]:.2f} per year\")\n",
    "print(\"This is closer to the true causal effect of $3000 per year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Causal Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between X and Z: 0.834\n",
      "Partial correlation between X and Z given Y: -0.090\n",
      "Near-zero partial correlation suggests that X and Z are conditionally independent given Y\n",
      "This supports the causal structure: X → Y → Z\n"
     ]
    }
   ],
   "source": [
    "# Simple causal discovery example\n",
    "# Generate data from a known causal structure: X → Y → Z\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "X = np.random.normal(0, 1, n)\n",
    "Y = 2*X + np.random.normal(0, 1, n)  # Y depends on X\n",
    "Z = 1.5*Y + np.random.normal(0, 1, n)  # Z depends on Y\n",
    "\n",
    "discovery_data = pd.DataFrame({'X': X, 'Y': Y, 'Z': Z})\n",
    "\n",
    "# Calculate conditional independence\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Correlation between X and Z\n",
    "corr_xz, _ = pearsonr(X, Z)\n",
    "print(f\"Correlation between X and Z: {corr_xz:.3f}\")\n",
    "\n",
    "# Partial correlation (X and Z given Y)\n",
    "# First, get residuals from regressing X on Y\n",
    "X_resid = sm.OLS(X, sm.add_constant(Y)).fit().resid\n",
    "# Then, get residuals from regressing Z on Y\n",
    "Z_resid = sm.OLS(Z, sm.add_constant(Y)).fit().resid\n",
    "# Calculate correlation between residuals\n",
    "partial_corr, _ = pearsonr(X_resid, Z_resid)\n",
    "\n",
    "print(f\"Partial correlation between X and Z given Y: {partial_corr:.3f}\")\n",
    "print(\"Near-zero partial correlation suggests that X and Z are conditionally independent given Y\")\n",
    "print(\"This supports the causal structure: X → Y → Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
